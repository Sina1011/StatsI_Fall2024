fa.sort(fit_inperson)
package_version("psych")
packageVersion("psych")
#load packages
library(readxl)
library(dplyr)
library(tidyr)
library(psych)
library(MBESS)
library(DescTools)
setwd("/Volumes/USB Daten verschlüsselt/Bachelorarbeit Daten")
#load data
data <- as.data.frame(read_xlsx("Datensatz_27.03.xlsx"))
sapply(data, class)
#identify all character columns
chars <- sapply(data[,4:28], is.character)
#convert all character columns to numeric
data[ , 4:28] <- as.data.frame(apply(data[ , 4:28], 2, as.numeric))
data <- data %>% fill(Geschlecht)
data_mean <- data %>%
group_by(Geschlecht, Nachname, Vorname,Fallnummer) %>%
summarise(across(c(1:25), mean, na.rm = TRUE))
#data with online/in-person
data[ , 4:28] <- as.data.frame(apply(data[ , 4:28], 2, as.numeric))
data <- data %>% fill(Geschlecht, Onl)
data_mean <- data %>%
group_by(Geschlecht, Nachname, Vorname, Onl) %>%
summarise(across(c(1:25), mean, na.rm = TRUE))
#subset data
data_onl<-subset(data_mean,Onl%in% c("Online"))
data_inperson<-subset(data_mean, Onl%in% c("Präsenz"))
fit<-fa(data_mean[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz","Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")],
fm="ml", rotate = "Promax",nfactors = 3, scores = "Bartlett")
fa.sort(fit)
fit_onl<-fa(data_onl[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz","Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")],
fm="ml", rotate = "Promax",nfactors = 2, scores = "Bartlett")
fa.sort(fit_onl)
fit_inperson<-fa(data_inperson[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz","Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")],
fm="ml", rotate = "Promax",nfactors = 2, scores = "Bartlett")
fa.sort(fit_inperson)
setwd("/Volumes/USB Daten verschlüsselt/Bachelorarbeit Daten")
#load packages
library(readxl)
library(dplyr)
library(tidyr)
library(psych)
library(MBESS)
library(DescTools)
#load data
data <- as.data.frame(read_xlsx("Datensatz_27.03.xlsx"))
sapply(data, class)
#identify all character columns
chars <- sapply(data[,4:28], is.character)
#convert all character columns to numeric
data[ , 4:28] <- as.data.frame(apply(data[ , 4:28], 2, as.numeric))
data <- data %>% fill(Geschlecht)
data_mean <- data %>%
group_by(Geschlecht, Nachname, Vorname,Fallnummer) %>%
summarise(across(c(1:25), mean, na.rm = TRUE))
#data with online/in-person
data[ , 4:28] <- as.data.frame(apply(data[ , 4:28], 2, as.numeric))
data <- data %>% fill(Geschlecht, Onl)
data_mean <- data %>%
group_by(Geschlecht, Nachname, Vorname, Onl) %>%
summarise(across(c(1:25), mean, na.rm = TRUE))
#subset data
data_onl<-subset(data_mean,Onl%in% c("Online"))
data_inperson<-subset(data_mean, Onl%in% c("Präsenz"))
#at least 50
data_fall_reduced_50 <- subset(data, Fallnummer%in% c("01/2008", "01/2019", "06/2007", "06/2015", "09/2007", "09/2010", "10/2015", "10/2018"))
fit_fall_reduced_50 <- aov(Gesamtbewertung~Fallnummer, data = data_fall_reduced_50)
summary(fit_fall_reduced_50)
#Varianzanalyse
data_fall <- data[data$Fallnummer != "01/2011", ]
fit_fall<- aov(Gesamtbewertung~Fallnummer, data = data_fall)
summary(fit_fall)
table(data$Fallnummer)
View(fit_fall_reduced_50)
#at least 50
data_fall_reduced_50 <- subset(data, Fallnummer%in% c("01/2008", "01/2019", "06/2007", "06/2015", "09/2007", "09/2010", "10/2015", "10/2018"))
fit_fall_reduced_50 <- aov(Gesamtbewertung~Fallnummer, data = data_fall_reduced_50)
summary(fit_fall_reduced_50)
EtaSq(fit_fall_reduced_50)
ci.pvaf(F.value = 2.844, df.1 = 7, df.2 = 504, N=512, conf.level = 0.95)
#factor analysis
#all
fa.parallel(data_mean[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz","Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")],
fm = "ml",
fa = "fa",
quant = 0.95,
n.iter = 1000)
fit<-fa(data_mean[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz","Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")],
fm="ml", rotate = "Promax",nfactors = 3, scores = "Bartlett")
fa.sort(fit)
fit<-fa(data_mean[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz","Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")],
fm="ml", rotate = "Promax",nfactors = 3, scores = "Bartlett")
fa.sort(fit)
#Faktor 1 - wie in Präsenz CFA
alpha(data_mean[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz")])
#Faktor 1 - mit wie in online CFA
alpha(data_mean[,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz", "Kooperationsfähigkeit/-bereitschaft","Konfliktmanagement")])
#Faktor 2 - wie in Präsenz CFA
alpha(data_mean[,c("Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")])
#Faktor 2 - wie in Online CFA
alpha(data_mean[,c("Teamfähigkeit","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative")])
#Faktor 3
alpha(data_mean[,c("Persönliche Präsentation", "Persönliches Auftreten")])
#Einflussfaktoren
data_complete <- na.omit(data_mean)
cormat <- cor(data_complete[ ,c("Persönliche Präsentation", "Persönliches Auftreten","Umgang mit den Fragen","Reaktion auf Nachfragen","Zuhören", "Einfühlen","Interaktion","Argumentation","Ausdrucksfähigkeit","Umgang mit Problematik des Falls","Kommunikationsfähigkeit/-kompetenz","Kooperationsfähigkeit/-bereitschaft","Teamfähigkeit","Konfliktmanagement","Stressbewältigung","Selbstmanagement","Kritikfähigkeit","Interesse am Beruf","Veränderungsbereitschaft","Entscheidungsfreude","Innovationsfähigkeit","Eigeninitiative", "Gesamtbewertung")])
val<-cormat[,"Gesamtbewertung"]
sort(val,decreasing = TRUE)
ls()
data()
Nilw
Nile
help(Nile)
mean(Nile)
plot(Nile)
min(Nile)
min(Time$Nile)
min(Nile$Time)
hist(Nile)
# create an object: assign a name and assign value(s) to it
x <- "Hello world"
x
ls()
#calculations
2 + 2
#create 7 random numbers between 0 and 1
runif(7)
z <- 2+2
z = 2+2
# "c" stands for concatenate so "y" here stores the values of 1, 2 and 4
y<-c(1,2,4)
#parts of individual objects can be accessed via square brackets
y[3]
#acces multiple parts of objects
y[2:3]
sum(y)
#store the outtput of a function in another object
z<-sum(y)
sqrt(962)
w<- sqrt(962)
#clearing our workspace
rm(list = ls())
x <- "Hello"
class(x)
#amount discrete values in one object
length(x)
#[] after an object name accesses an element x[1] would be "Hello" but we can add
x[2]<- "world"
x
length(x)
#create object made of 50 "random"numbers drawn from notmal distribution
x<-rnorm(n=50)
mean(x)
sd(x)
#extract element from vector
vec2 <- c(alpha=1, beta=2, gamma=3)
length(x)
y<-x
y<-2*y
#linear model function to apply lienar regression
xylm <- lm(y~)x)
#linear model function to apply lienar regression
xylm <- lm(y~x)
attributes(xylm)
summary(xylm)
plot(x,y)
#lm creates residuals, access subobject with $ (higher level object first)
xylm$residuals
#express iterative beahvior implicitly by creating loops
#example for vector
x<-vector("double", 10)
for (i in 1:10) {
}
x[i] <-i
x<-vector("double", 10)
for (i in 1:10) {
x[i] <-i
}
#lm creates residuals, access subobject with $ (higher level object first)
xylm$residuals
x<-vector("double", 10)
for (i in 1:10) {
x[i
x<-vector("double", 10)
x<-vector("double", 10)
for (i in 1:10) {
x[i] <-i
}
#right
y<- (x,11)
#add a number to a sequence: DO NOT just type +y at the end
#wrong
y<-x+11
#right
y<-(x,11)
#right
y<-(x , 11)
#right
y<-c(x , 11)
search()
install.packages("tidyverse")
# how to ask for help
help(tidyverse)
# how to ask for help
help("tidyverse")
# how to ask for help
help(tidyverse)
?tidyverse
?persp
?dplyr
veignette("dplyr")
?mtcars
summary(mtcars)
str(mtcars)
head(mtcars)
install.packages("ggplot2")
mtcars$am <- as.factor(mtcars$am)
mtcars$am <- as.factor(mtcars$am)
mtcars$cyl <- as.factor(mtcars$cyl)
ggplot(mtcars, aes(wt, mpg, size = hp)) +
geom_text(aes(size = hp, label = cyl, color = am)) +
geom_smooth(aes(linetype = cyl), color = "grey", size = 0.5, se = FALSE, show.legend = FALSE) +
guides(size = "none") +
theme_classic() +
theme(legend.title = element_blank(), legend.justification = c(1, 1), legend.position = c(1, 1)) +
scale_color_manual(labels = c("manual", "automatic"), values = c("blue", "red")) +
labs(title = "Plot of Fuel Efficiency by Weight for 32 Cars", subtitle = "Number of cylinders; size = horsepower") +
xlab("weight (1000 lbs)")
load(ggplot2)
load("ggplot2")
install.packages("ggplot2")
load("ggplot2")
ggplot(mtcars, aes(wt, mpg, size = hp)) +
geom_text(aes(size = hp, label = cyl, color = am)) +
geom_smooth(aes(linetype = cyl), color = "grey", size = 0.5, se = FALSE, show.legend = FALSE) +
guides(size = "none") +
theme_classic() +
theme(legend.title = element_blank(), legend.justification = c(1, 1), legend.position = c(1, 1)) +
scale_color_manual(labels = c("manual", "automatic"), values = c("blue", "red")) +
labs(title = "Plot of Fuel Efficiency by Weight for 32 Cars", subtitle = "Number of cylinders; size = horsepower") +
xlab("weight (1000 lbs)")
library(ggplot2)
ggplot(mtcars, aes(wt, mpg, size = hp)) +
geom_text(aes(size = hp, label = cyl, color = am)) +
geom_smooth(aes(linetype = cyl), color = "grey", size = 0.5, se = FALSE, show.legend = FALSE) +
guides(size = "none") +
theme_classic() +
theme(legend.title = element_blank(), legend.justification = c(1, 1), legend.position = c(1, 1)) +
scale_color_manual(labels = c("manual", "automatic"), values = c("blue", "red")) +
labs(title = "Plot of Fuel Efficiency by Weight for 32 Cars", subtitle = "Number of cylinders; size = horsepower") +
xlab("weight (1000 lbs)")
getwd()
?setwd()
library(tidyverse)
summary(diamonds)
#clearing our workspace
rm(list = ls())
library(tidyverse)
summary(diamonds)
head(diamonds)
#create histogram of values for price with base R
hist(diamonds$price, col = "steelblue",
main = "Histogram of Price Values",
xlab = "Price")
#create histogram of values for price with ggplot2
ggplot(data=diamonds, aes(x=price)) +
geom_histogram(fill="steelblue", color="black") +
ggtitle("Histogram of Price Values")
an_object <- diamonds[diamonds$cut == "Ideal",]
anotherObject <- diamonds[diamonds$cut == "Premium",]
Object3 <- diamonds[diamonds$cut == "Very Good", ]
mean(an_object$price)
mean(anotherObject)
View(anotherObject)
mean(anotherObject$price)
mean()
mean(Object3$price)
diamonds %>%
filter(cut %in% c("Ideal", "Premium", "Very Good")) %>%
group_by(cut) %>%
ggplot(aes(cut, price)) +
geom_boxplot()
class(diamonds$cut)
levels(diamonds$cut)
mean(diamonds$carat)
diamonds %>%
filter(cut %in% c("Ideal", "Premium", "Very Good")) %>%
group_by(cut) %>%
ggplot(aes(cut, price)) +
geom_boxplot()
diamonds %>%
filter(cut %in% c("Ideal", "Premium", "Very Good")) %>%
group_by(cut) %>%
ggplot(aes(carat, price, color = cut)) +
geom_point(alpha = 0.2) +
geom_smooth()
diamonds %>%
filter(cut %in% c("Ideal", "Premium", "Very Good")) %>%
group_by(cut) %>%
ggplot(aes(carat, price, color = cut)) +
geom_smooth() +
theme_classic() +
labs(title = "Pick a good title for this plot")
ggsave("Name this plot.pdf")
write_csv(diamonds, "Name this data.csv")
chi_df <- read.csv("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/timeseries/containment_health_index_avg.csv")
str(chi_df) #overall structure
dim(chi_df) #dimensions
# install.packages("rjson")
library(rjson)
#Function from the package that works here (quick google search will tell)
dublin <- fromJSON(file = "https://prodapi.metweb.ie/monthly-data/Dublin%20Airport")
str(dublin) # What format is here?
#To access the element that contains the monthly average we can
# use a dolar sign as if it was a column, as save as a dataframe
dublin_df <- as.data.frame(dublin$total_rainfall)
str(dublin_df)
View(dublin_df)
colnames(dublin_df)
# Roches Point, Co Cork
# https://data.gov.ie/dataset/monthly-weather-roches-point?package_type=dataset
cork <- fromJSON(file = "https://prodapi.metweb.ie/monthly-data/Roches%20point")
cork_df <- as.data.frame(cork$total_rainfall)
# Comparing if the dataframes have the same dimensions
dim(dublin_df) == dim(cork_df)
# Malin head, Co Donegal
# https://data.gov.ie/dataset/monthly-weather-malin-head?package_type=dataset
donegal <- fromJSON (file = "https://prodapi.metweb.ie/monthly-data/Malin%20Head")
donegal_df <- as.data.frame(donegal$total_rainfall)
# Now let's merge these three rows in the same dataframe
rain_df <- do.call("rbind", list(dublin = dublin_df,
cork = cork_df,
donegal = donegal_df))
str(rain_df)
#Drop columns that contain annual averages
rain_df <- rain_df[,!endsWith(colnames(rain_df),"annual")]
#Drop columns that contain report.LTA.
rain_df <- rain_df[,!startsWith(colnames(rain_df),"report.LTA.")]
#Transforming in numeric
rain_df <- data.frame(lapply(rain_df, function(x) as.numeric(x)))
#Drop columns where all values are missing (August-December 2023)
rain_df <- rain_df[,colSums(is.na(rain_df))<nrow(rain_df)]
#New column with county names
rownames(rain_df)<- c("Dublin", "Cork", "Donegal")
#transposing so we have the dates on the rows and counties on columns
rain_df <- data.frame(t(rain_df[-1]))
# Specify par parameters
par(mar = c(5, 4, 4, 8),
xpd = TRUE)
# Create a blank plot with custom axis labels and a legend
plot(1, type = "n", xlim = c(1, length(rain_df$Dublin)), ylim = c(0, max(rain_df$Dublin, rain_df$Cork, rain_df$Donegal)),
ylab = "Rainfall (mm)", xlab = "Month", main = "Monthly Rainfall Comparison")
# Add lines for each dataset with different colors and labels
lines(rain_df$Dublin, type = "l", col = "blue", lwd = 1, lty = 1, xaxt = "n", yaxt = "n", ann = FALSE)
lines(rain_df$Cork, type = "l", col = "red", lwd = 1, lty = 2)
lines(rain_df$Donegal, type = "l", col = "green", lwd = 1, lty = 3)
# Add a legend
legend("topright",inset = c(- 0.5, 0), legend = c("Dublin", "Cork", "Donegal"), col = c("blue", "red", "green"),
lty = c(1, 2, 3), lwd = 1, bg = "white", xpd = TRUE, y.intersp = ,2, title = "Locations")
#dev.off function to reset par to default setting
dev.off()
# install.packages("ggtext")
library(ggtext)
View(ToothGrowth)
plot_data <- ToothGrowth %>%
mutate(dose = factor(dose)) %>%
group_by(dose, supp) %>%
summarise(len = mean(len)) %>%
ungroup()
# Unstyled plot
ggplot(
data = plot_data,
mapping = aes(x = len, y = dose, fill = supp)
) +
geom_col(position = "dodge")
# Styled plot
ggplot(
data = plot_data,
mapping = aes(x = len, y = dose, fill = supp)
) +
geom_col(
position = position_dodge(width = 0.7),
width = 0.7
) +
scale_x_continuous(
limits = c(0, 30),
name = "Tooth length"
) +
geom_text(
mapping = aes(label = round(len, 0)),
position = position_dodge(width = 0.7),
hjust = 1.5,
size = 6,
fontface = "bold",
colour = "white"
) +
scale_fill_manual(values = c("#9B1D20", "#3D5A80")) +
labs(title = "Tooth Growth",
subtitle = "Each of 60 guinea pigs received one of three dose levels of
vitamin C (0.5, 1, and 2 mg/day) by one of two delivery methods:
<span style='color: #9B1D20'>**orange juice**</span> or
<span style='color: #3D5A80'>**ascorbic acid**</span>.",
y = "Dosage (mg/day)"
) +
theme_minimal(base_size = 14) +
theme(
legend.position = "none",
plot.title = element_textbox_simple(face = "bold"),
plot.subtitle = element_textbox_simple(
margin = margin(t = 10),
lineheight = 1.5
),
plot.title.position = "plot",
plot.margin = margin(15, 10, 10, 15),
panel.grid = element_blank(),
axis.text.x = element_blank()
)
IRkernel::installspec()
install.packages("devtools")
devtools::install_github("IRkernel/IRkernel")
IRkernel::installspec()
IRkernel::installspec()
install.packages("devtools")
devtools::install_github("IRkernel/IRkernel")
##load dataset
dataset_edu<-c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##1. calculate confidence interval
length(dataset_edu) #=25
conf_up<- mean(dataset_edu)+qnorm((1-0.90)/2, lower.tail = FALSE)*(sd(dataset_edu)/sqrt(25))
conf_low<- mean(dataset_edu)-qnorm((1-0.90)/2, lower.tail = FALSE)*(sd(dataset_edu)/sqrt(25))
t.test(dataset_edu, mu = 100, alternative = "greater")
##load dataset
dataset_edu<-c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##1. calculate confidence interval
length(dataset_edu) #=25
conf_up<- mean(dataset_edu)+qnorm((1-0.90)/2, lower.tail = FALSE)*(sd(dataset_edu)/sqrt(25))
conf_low<- mean(dataset_edu)-qnorm((1-0.90)/2, lower.tail = FALSE)*(sd(dataset_edu)/sqrt(25))
t.test(dataset_edu, mu = 100, alternative = "greater")
View(cork)
#Question 1: Education
rm()
#Question 1: Education
rm(ls())
#Question 1: Education
rm(list=ls())
##load dataset
dataset_edu<-c(105, 69, 86, 100, 82, 111, 104, 110, 87, 108, 87, 90, 94, 113, 112, 98, 80, 97, 95, 111, 114, 89, 95, 126, 98)
##1. calculate confidence interval
length(dataset_edu) #=25
conf_up<- mean(dataset_edu)+qnorm((1-0.90)/2, lower.tail = FALSE)*(sd(dataset_edu)/sqrt(25))
conf_low<- mean(dataset_edu)-qnorm((1-0.90)/2, lower.tail = FALSE)*(sd(dataset_edu)/sqrt(25))
t.test(dataset_edu, mu = 100, alternative = "greater")
?qt
t_score <- qt(0.95, df=25-1)
##1. calculate confidence interval
length(dataset_edu) #=25
conf_high <- mean(dataset_edu)+(t_score)*(sd(dataset_edu)/sqrt(25)))
conf_high <- mean(dataset_edu)+(t_score)*(sd(dataset_edu)/sqrt(25))
conf_low <- mean(dataset_edu)-(t_score)*(sd(dataset_edu)/sqrt(25))
t.test(dataset_edu, mu = 100, alternative = "greater")
t.test(dataset_edu, alternative = "greater")
#Problem Set 2
#Question 1: Political Science
##a. calculate chi-square test statistic
#sum of (number of observances - number of expectance if fully independent samples)^2/number expected
#calculate f1e = expected if independent for upper class not stopped
#row total/grand total * column total
(14+6+7)/(14+6+7+7+7+1)*(14+7)
#Problem Set 2
#Question 1: Political Science
##a. calculate chi-square test statistic
#sum of (number of observances - number of expectance if fully independent samples)^2/number expected
#calculate f1e = expected if independent for upper class not stopped
#row total/grand total * column total
up_not<-(14+6+7)/(14+6+7+7+7+1)*(14+7)
up_bribe<-(14+6+7)/(14+6+7+7+7+1)*(6+7)
up_stop<-(14+6+7)/(14+6+7+7+7+1)*(1+7)
low_not<-(7+7+1)/(14+6+7+7+7+1)*(14+7)
low_bribe<-(7+7+1)/(14+6+7+7+7+1)*(6+7)
low_stop<-(7+7+1)/(14+6+7+7+7+1)*(1+7)
##chi-square stat
((14-up_not)^2/up_not)+((6-up_bribe)^2/up_bribe)+((7-up_stop)^2/up_stop)+
((7-low_not)^2/low_not)+((7-low_bribe)^2/low_bribe)+ ((1-low_stop)^2/low_stop)
##chi-square stat
chi_square<-((14-up_not)^2/up_not)+((6-up_bribe)^2/up_bribe)+((7-up_stop)^2/up_stop)+
((7-low_not)^2/low_not)+((7-low_bribe)^2/low_bribe)+ ((1-low_stop)^2/low_stop)
##b. calculate p for chi-square
pchisq(chi_square, df=1*2, lower.tail = FALSE)
##c. standardized residuals
## (fobserved-fexpected)/standard error (sqrt((1-row proportion)*(1- column proportion))
res_up_not <- (14-up_not)/sqrt((1-(27/42))*(1-(21/42)))
res_up_bribe <- (6-up_bribe)/sqrt((1-(27/42))*(1-(13/42)))
res_up_stop <- (7-up_stop)/sqrt((1-(27/42))*(1-(8/42)))
res_low_not <- (7-up_not)/sqrt((1-(15/42))*(1-(21/42)))
res_low_bribe <- (7-up_not)/sqrt((1-(15/42))*(1-(13/42)))
res_low_not <- (7-low_not)/sqrt((1-(15/42))*(1-(21/42)))
res_low_bribe <- (7-low_bribe)/sqrt((1-(15/42))*(1-(13/42)))
res_low_stop <- (1-low_stop)/sqrt((1-(15/42))*(1-(8/42)))
setwd("/Users/sinalangenscheidt/Documents/Applied Statistical Anaylsis I/GitHub/StatsI_Fall2024/my_answers")
#2.
##b. bivariate regression in R
read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
#2.
##b. bivariate regression in R
women_df<-read.csv("https://raw.githubusercontent.com/kosukeimai/qss/master/PREDICTION/women.csv")
View(women_df)
lm(women_df$water~women_df$reserved, data = women_df)
lm(water~reserved, data = women_df)
